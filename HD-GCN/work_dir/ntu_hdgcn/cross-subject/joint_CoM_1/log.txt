[ Wed May  3 16:53:20 2023 ] using warm up, epoch: 5
[ Wed May  3 16:59:14 2023 ] using warm up, epoch: 5
[ Wed May  3 17:10:21 2023 ] using warm up, epoch: 5
[ Wed May  3 17:22:08 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 90, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Wed May  3 17:22:08 2023 ] # Parameters: 1659980
[ Wed May  3 17:22:08 2023 ] Training epoch: 1
[ Thu May  4 02:07:18 2023 ] using warm up, epoch: 5
[ Thu May  4 02:07:41 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 90, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Thu May  4 02:07:41 2023 ] # Parameters: 1659980
[ Thu May  4 02:07:41 2023 ] Training epoch: 1
[ Thu May  4 02:08:14 2023 ] using warm up, epoch: 5
[ Thu May  4 02:08:32 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 32, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'test', 'window_size': 32, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 90, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Thu May  4 02:08:32 2023 ] # Parameters: 1659980
[ Thu May  4 02:08:32 2023 ] Training epoch: 1
[ Thu May  4 02:09:26 2023 ] using warm up, epoch: 5
[ Thu May  4 02:09:44 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'test', 'window_size': 32, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 90, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Thu May  4 02:09:44 2023 ] # Parameters: 1659980
[ Thu May  4 02:09:44 2023 ] Training epoch: 1
[ Thu May  4 02:10:09 2023 ] using warm up, epoch: 5
[ Thu May  4 02:10:26 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 32, 'test_batch_size': 32, 'start_epoch': 0, 'num_epoch': 10, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Thu May  4 02:10:26 2023 ] # Parameters: 1659980
[ Thu May  4 02:10:26 2023 ] Training epoch: 1
[ Thu May  4 02:12:20 2023 ] using warm up, epoch: 5
[ Thu May  4 02:12:38 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 16, 'test_batch_size': 16, 'start_epoch': 0, 'num_epoch': 10, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Thu May  4 02:12:38 2023 ] # Parameters: 1659980
[ Thu May  4 02:12:38 2023 ] Training epoch: 1
[ Thu May  4 02:13:41 2023 ] using warm up, epoch: 5
[ Thu May  4 02:13:59 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 16, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'test', 'window_size': 16, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 16, 'test_batch_size': 16, 'start_epoch': 0, 'num_epoch': 10, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Thu May  4 02:13:59 2023 ] # Parameters: 1659980
[ Thu May  4 02:13:59 2023 ] Training epoch: 1
[ Thu May  4 02:14:08 2023 ] using warm up, epoch: 5
[ Thu May  4 02:14:26 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 4, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 16, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'test', 'window_size': 16, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 16, 'test_batch_size': 16, 'start_epoch': 0, 'num_epoch': 10, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Thu May  4 02:14:26 2023 ] # Parameters: 1659980
[ Thu May  4 02:14:26 2023 ] Training epoch: 1
[ Thu May  4 02:33:46 2023 ] 	Mean training loss: 2.1544.  Mean training acc: 38.97%.
[ Thu May  4 02:33:46 2023 ] 	Learning Rate: 0.0200
[ Thu May  4 02:33:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 02:33:46 2023 ] Eval epoch: 1
[ Thu May  4 18:17:48 2023 ] using warm up, epoch: 5
[ Thu May  4 18:18:11 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 3, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 32, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/NTU60_CS.npz', 'split': 'test', 'window_size': 32, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 32, 'test_batch_size': 32, 'start_epoch': 0, 'num_epoch': 10, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Thu May  4 18:18:11 2023 ] # Parameters: 1659980
[ Thu May  4 18:18:11 2023 ] Training epoch: 1
[ Thu May  4 18:30:56 2023 ] 	Mean training loss: 2.2111.  Mean training acc: 37.57%.
[ Thu May  4 18:30:56 2023 ] 	Learning Rate: 0.0200
[ Thu May  4 18:30:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 18:30:57 2023 ] Eval epoch: 1
[ Thu May  4 18:32:05 2023 ] 	Mean test loss of 516 batches: 1.4928551206524059.
[ Thu May  4 18:32:05 2023 ] 	Top1: 55.07%
[ Thu May  4 18:32:05 2023 ] 	Top5: 87.63%
[ Thu May  4 18:32:05 2023 ] Training epoch: 2
[ Thu May  4 18:44:56 2023 ] 	Mean training loss: 1.4119.  Mean training acc: 57.32%.
[ Thu May  4 18:44:56 2023 ] 	Learning Rate: 0.0400
[ Thu May  4 18:44:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 18:44:56 2023 ] Eval epoch: 2
[ Thu May  4 18:46:04 2023 ] 	Mean test loss of 516 batches: 1.3653517735096836.
[ Thu May  4 18:46:04 2023 ] 	Top1: 57.82%
[ Thu May  4 18:46:04 2023 ] 	Top5: 89.93%
[ Thu May  4 18:46:04 2023 ] Training epoch: 3
[ Thu May  4 18:58:52 2023 ] 	Mean training loss: 1.1390.  Mean training acc: 65.02%.
[ Thu May  4 18:58:52 2023 ] 	Learning Rate: 0.0600
[ Thu May  4 18:58:52 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 18:58:53 2023 ] Eval epoch: 3
[ Thu May  4 19:00:03 2023 ] 	Mean test loss of 516 batches: 1.147700601495629.
[ Thu May  4 19:00:03 2023 ] 	Top1: 66.08%
[ Thu May  4 19:00:04 2023 ] 	Top5: 91.93%
[ Thu May  4 19:00:04 2023 ] Training epoch: 4
[ Thu May  4 19:12:55 2023 ] 	Mean training loss: 1.0379.  Mean training acc: 68.12%.
[ Thu May  4 19:12:55 2023 ] 	Learning Rate: 0.0800
[ Thu May  4 19:12:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 19:12:56 2023 ] Eval epoch: 4
[ Thu May  4 19:14:02 2023 ] 	Mean test loss of 516 batches: 1.0039629151452651.
[ Thu May  4 19:14:02 2023 ] 	Top1: 69.15%
[ Thu May  4 19:14:03 2023 ] 	Top5: 93.80%
[ Thu May  4 19:14:03 2023 ] Training epoch: 5
[ Thu May  4 19:26:53 2023 ] 	Mean training loss: 1.0104.  Mean training acc: 68.67%.
[ Thu May  4 19:26:53 2023 ] 	Learning Rate: 0.1000
[ Thu May  4 19:26:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 19:26:53 2023 ] Eval epoch: 5
[ Thu May  4 19:28:00 2023 ] 	Mean test loss of 516 batches: 1.031665093099424.
[ Thu May  4 19:28:01 2023 ] 	Top1: 68.59%
[ Thu May  4 19:28:01 2023 ] 	Top5: 93.55%
[ Thu May  4 19:28:01 2023 ] Training epoch: 6
[ Thu May  4 19:40:51 2023 ] 	Mean training loss: 0.9360.  Mean training acc: 70.87%.
[ Thu May  4 19:40:51 2023 ] 	Learning Rate: 0.0905
[ Thu May  4 19:40:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 19:40:51 2023 ] Eval epoch: 6
[ Thu May  4 19:41:58 2023 ] 	Mean test loss of 516 batches: 0.9130006324889701.
[ Thu May  4 19:41:59 2023 ] 	Top1: 72.13%
[ Thu May  4 19:41:59 2023 ] 	Top5: 94.87%
[ Thu May  4 19:41:59 2023 ] Training epoch: 7
[ Thu May  4 19:54:47 2023 ] 	Mean training loss: 0.8375.  Mean training acc: 73.93%.
[ Thu May  4 19:54:47 2023 ] 	Learning Rate: 0.0655
[ Thu May  4 19:54:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 19:54:48 2023 ] Eval epoch: 7
[ Thu May  4 19:55:59 2023 ] 	Mean test loss of 516 batches: 0.7746105185428331.
[ Thu May  4 19:56:00 2023 ] 	Top1: 76.24%
[ Thu May  4 19:56:00 2023 ] 	Top5: 95.65%
[ Thu May  4 19:56:00 2023 ] Training epoch: 8
[ Thu May  4 20:08:49 2023 ] 	Mean training loss: 0.7016.  Mean training acc: 77.96%.
[ Thu May  4 20:08:49 2023 ] 	Learning Rate: 0.0346
[ Thu May  4 20:08:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 20:08:49 2023 ] Eval epoch: 8
[ Thu May  4 20:09:59 2023 ] 	Mean test loss of 516 batches: 0.6953083176685627.
[ Thu May  4 20:09:59 2023 ] 	Top1: 79.25%
[ Thu May  4 20:09:59 2023 ] 	Top5: 96.40%
[ Thu May  4 20:09:59 2023 ] Training epoch: 9
[ Thu May  4 20:22:47 2023 ] 	Mean training loss: 0.5281.  Mean training acc: 83.31%.
[ Thu May  4 20:22:47 2023 ] 	Learning Rate: 0.0097
[ Thu May  4 20:22:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 20:22:47 2023 ] Eval epoch: 9
[ Thu May  4 20:23:56 2023 ] 	Mean test loss of 516 batches: 0.4865782462374502.
[ Thu May  4 20:23:57 2023 ] 	Top1: 84.93%
[ Thu May  4 20:23:57 2023 ] 	Top5: 97.47%
[ Thu May  4 20:23:57 2023 ] Training epoch: 10
[ Thu May  4 20:36:46 2023 ] 	Mean training loss: 0.3887.  Mean training acc: 87.70%.
[ Thu May  4 20:36:46 2023 ] 	Learning Rate: 0.0001
[ Thu May  4 20:36:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu May  4 20:36:47 2023 ] Eval epoch: 10
[ Thu May  4 20:37:56 2023 ] 	Mean test loss of 516 batches: 0.44847410821532757.
[ Thu May  4 20:37:56 2023 ] 	Top1: 86.21%
[ Thu May  4 20:37:56 2023 ] 	Top5: 97.84%
[ Thu May  4 20:39:06 2023 ] Best accuracy: 0.8620731485412749
[ Thu May  4 20:39:06 2023 ] Epoch number: 10
[ Thu May  4 20:39:06 2023 ] Model name: ./work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/
[ Thu May  4 20:39:06 2023 ] Model total number of params: 1659980
[ Thu May  4 20:39:06 2023 ] Weight decay: 0.0004
[ Thu May  4 20:39:06 2023 ] Base LR: 0.1
[ Thu May  4 20:39:06 2023 ] Batch Size: 32
[ Thu May  4 20:39:06 2023 ] Test Batch Size: 32
[ Thu May  4 20:39:06 2023 ] seed: 1
[ Sat May 13 15:03:03 2023 ] using warm up, epoch: 5
[ Sat May 13 15:06:33 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 3, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/hdgcn_filtered/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 32, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/hdgcn_filtered/NTU60_CS.npz', 'split': 'test', 'window_size': 32, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 16, 'test_batch_size': 16, 'start_epoch': 0, 'num_epoch': 10, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Sat May 13 15:06:33 2023 ] # Parameters: 1659980
[ Sat May 13 15:06:33 2023 ] Training epoch: 1
[ Sat May 13 15:10:01 2023 ] 	Mean training loss: 4.3562.  Mean training acc: 1.59%.
[ Sat May 13 15:10:01 2023 ] 	Learning Rate: 0.0200
[ Sat May 13 15:10:01 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat May 13 15:10:02 2023 ] Eval epoch: 1
[ Sat May 13 15:10:27 2023 ] 	Mean test loss of 280 batches: 4.146485886403492.
[ Sat May 13 15:10:27 2023 ] 	Top1: 1.45%
[ Sat May 13 15:10:27 2023 ] 	Top5: 8.30%
[ Sat May 13 15:10:27 2023 ] Training epoch: 2
[ Sat May 13 15:12:53 2023 ] using warm up, epoch: 5
[ Sat May 13 15:15:55 2023 ] Parameters:
{'work_dir': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/', 'model_saved_name': './work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/runs', 'config': '/home/prgc/acrionreco-with-noisy-data-topic-c/HD-GCN/config/nturgbd-cross-subject/joint_com_1.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 3, 'train_feeder_args': {'data_path': '/cvhci/temp/prgc/hdgcn_filtered/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 32, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'bone': False}, 'test_feeder_args': {'data_path': '/cvhci/temp/prgc/hdgcn_filtered/NTU60_CS.npz', 'split': 'test', 'window_size': 32, 'p_interval': [0.95], 'bone': False, 'debug': False}, 'model': 'model.HDGCN.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d_hierarchy.Graph', 'graph_args': {'labeling_mode': 'spatial', 'CoM': 1}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 40, 60], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 16, 'test_batch_size': 16, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0004, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'loss_type': 'CE'}

[ Sat May 13 15:15:55 2023 ] # Parameters: 1659980
[ Sat May 13 15:15:55 2023 ] Training epoch: 1
[ Sat May 13 15:18:58 2023 ] 	Mean training loss: 4.3562.  Mean training acc: 1.59%.
[ Sat May 13 15:18:58 2023 ] 	Learning Rate: 0.0200
[ Sat May 13 15:18:58 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:18:58 2023 ] Eval epoch: 1
[ Sat May 13 15:19:23 2023 ] 	Mean test loss of 280 batches: 4.146485886403492.
[ Sat May 13 15:19:23 2023 ] 	Top1: 1.45%
[ Sat May 13 15:19:23 2023 ] 	Top5: 8.30%
[ Sat May 13 15:19:23 2023 ] Training epoch: 2
[ Sat May 13 15:22:27 2023 ] 	Mean training loss: 4.1270.  Mean training acc: 1.39%.
[ Sat May 13 15:22:28 2023 ] 	Learning Rate: 0.0400
[ Sat May 13 15:22:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:22:28 2023 ] Eval epoch: 2
[ Sat May 13 15:22:53 2023 ] 	Mean test loss of 280 batches: 4.114278898068837.
[ Sat May 13 15:22:53 2023 ] 	Top1: 1.57%
[ Sat May 13 15:22:53 2023 ] 	Top5: 8.03%
[ Sat May 13 15:22:53 2023 ] Training epoch: 3
[ Sat May 13 15:25:57 2023 ] 	Mean training loss: 4.1218.  Mean training acc: 1.75%.
[ Sat May 13 15:25:57 2023 ] 	Learning Rate: 0.0600
[ Sat May 13 15:25:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:25:58 2023 ] Eval epoch: 3
[ Sat May 13 15:26:22 2023 ] 	Mean test loss of 280 batches: 4.110242942401341.
[ Sat May 13 15:26:22 2023 ] 	Top1: 1.72%
[ Sat May 13 15:26:22 2023 ] 	Top5: 8.53%
[ Sat May 13 15:26:22 2023 ] Training epoch: 4
[ Sat May 13 15:29:26 2023 ] 	Mean training loss: 4.1165.  Mean training acc: 1.52%.
[ Sat May 13 15:29:26 2023 ] 	Learning Rate: 0.0800
[ Sat May 13 15:29:26 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:29:27 2023 ] Eval epoch: 4
[ Sat May 13 15:29:51 2023 ] 	Mean test loss of 280 batches: 4.106014737061092.
[ Sat May 13 15:29:51 2023 ] 	Top1: 1.54%
[ Sat May 13 15:29:51 2023 ] 	Top5: 8.50%
[ Sat May 13 15:29:52 2023 ] Training epoch: 5
[ Sat May 13 15:32:55 2023 ] 	Mean training loss: 4.1152.  Mean training acc: 1.46%.
[ Sat May 13 15:32:55 2023 ] 	Learning Rate: 0.1000
[ Sat May 13 15:32:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:32:56 2023 ] Eval epoch: 5
[ Sat May 13 15:33:20 2023 ] 	Mean test loss of 280 batches: 4.113536778518132.
[ Sat May 13 15:33:20 2023 ] 	Top1: 1.79%
[ Sat May 13 15:33:20 2023 ] 	Top5: 8.39%
[ Sat May 13 15:33:21 2023 ] Training epoch: 6
[ Sat May 13 15:36:24 2023 ] 	Mean training loss: 4.1118.  Mean training acc: 1.60%.
[ Sat May 13 15:36:24 2023 ] 	Learning Rate: 0.0999
[ Sat May 13 15:36:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:36:25 2023 ] Eval epoch: 6
[ Sat May 13 15:36:50 2023 ] 	Mean test loss of 280 batches: 4.106255252020699.
[ Sat May 13 15:36:50 2023 ] 	Top1: 1.66%
[ Sat May 13 15:36:50 2023 ] 	Top5: 7.99%
[ Sat May 13 15:36:50 2023 ] Training epoch: 7
[ Sat May 13 15:39:54 2023 ] 	Mean training loss: 4.1093.  Mean training acc: 1.38%.
[ Sat May 13 15:39:54 2023 ] 	Learning Rate: 0.0995
[ Sat May 13 15:39:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:39:55 2023 ] Eval epoch: 7
[ Sat May 13 15:40:19 2023 ] 	Mean test loss of 280 batches: 4.104841038158962.
[ Sat May 13 15:40:19 2023 ] 	Top1: 1.70%
[ Sat May 13 15:40:19 2023 ] 	Top5: 8.59%
[ Sat May 13 15:40:19 2023 ] Training epoch: 8
[ Sat May 13 15:43:23 2023 ] 	Mean training loss: 4.1107.  Mean training acc: 1.67%.
[ Sat May 13 15:43:23 2023 ] 	Learning Rate: 0.0989
[ Sat May 13 15:43:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:43:24 2023 ] Eval epoch: 8
[ Sat May 13 15:43:48 2023 ] 	Mean test loss of 280 batches: 4.102324889387403.
[ Sat May 13 15:43:48 2023 ] 	Top1: 1.66%
[ Sat May 13 15:43:48 2023 ] 	Top5: 8.12%
[ Sat May 13 15:43:49 2023 ] Training epoch: 9
[ Sat May 13 15:46:52 2023 ] 	Mean training loss: 4.1089.  Mean training acc: 1.61%.
[ Sat May 13 15:46:52 2023 ] 	Learning Rate: 0.0981
[ Sat May 13 15:46:52 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:46:53 2023 ] Eval epoch: 9
[ Sat May 13 15:47:17 2023 ] 	Mean test loss of 280 batches: 4.106728223391942.
[ Sat May 13 15:47:17 2023 ] 	Top1: 1.81%
[ Sat May 13 15:47:17 2023 ] 	Top5: 8.84%
[ Sat May 13 15:47:18 2023 ] Training epoch: 10
[ Sat May 13 15:50:21 2023 ] 	Mean training loss: 4.1066.  Mean training acc: 1.71%.
[ Sat May 13 15:50:21 2023 ] 	Learning Rate: 0.0970
[ Sat May 13 15:50:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:50:22 2023 ] Eval epoch: 10
[ Sat May 13 15:50:46 2023 ] 	Mean test loss of 280 batches: 4.109829616546631.
[ Sat May 13 15:50:46 2023 ] 	Top1: 1.70%
[ Sat May 13 15:50:46 2023 ] 	Top5: 8.24%
[ Sat May 13 15:50:47 2023 ] Training epoch: 11
[ Sat May 13 15:53:50 2023 ] 	Mean training loss: 4.1074.  Mean training acc: 1.71%.
[ Sat May 13 15:53:50 2023 ] 	Learning Rate: 0.0957
[ Sat May 13 15:53:50 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:53:51 2023 ] Eval epoch: 11
[ Sat May 13 15:54:16 2023 ] 	Mean test loss of 280 batches: 4.117750064815794.
[ Sat May 13 15:54:16 2023 ] 	Top1: 1.63%
[ Sat May 13 15:54:16 2023 ] 	Top5: 8.42%
[ Sat May 13 15:54:16 2023 ] Training epoch: 12
[ Sat May 13 15:57:20 2023 ] 	Mean training loss: 4.1059.  Mean training acc: 1.80%.
[ Sat May 13 15:57:20 2023 ] 	Learning Rate: 0.0942
[ Sat May 13 15:57:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 15:57:21 2023 ] Eval epoch: 12
[ Sat May 13 15:57:45 2023 ] 	Mean test loss of 280 batches: 4.105043062993459.
[ Sat May 13 15:57:45 2023 ] 	Top1: 1.97%
[ Sat May 13 15:57:45 2023 ] 	Top5: 8.21%
[ Sat May 13 15:57:45 2023 ] Training epoch: 13
[ Sat May 13 16:00:49 2023 ] 	Mean training loss: 4.1069.  Mean training acc: 1.85%.
[ Sat May 13 16:00:49 2023 ] 	Learning Rate: 0.0924
[ Sat May 13 16:00:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:00:50 2023 ] Eval epoch: 13
[ Sat May 13 16:01:14 2023 ] 	Mean test loss of 280 batches: 4.10396009683609.
[ Sat May 13 16:01:14 2023 ] 	Top1: 1.95%
[ Sat May 13 16:01:14 2023 ] 	Top5: 8.35%
[ Sat May 13 16:01:14 2023 ] Training epoch: 14
[ Sat May 13 16:04:18 2023 ] 	Mean training loss: 4.1076.  Mean training acc: 1.53%.
[ Sat May 13 16:04:18 2023 ] 	Learning Rate: 0.0905
[ Sat May 13 16:04:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:04:19 2023 ] Eval epoch: 14
[ Sat May 13 16:04:44 2023 ] 	Mean test loss of 280 batches: 4.103132363728115.
[ Sat May 13 16:04:44 2023 ] 	Top1: 1.54%
[ Sat May 13 16:04:44 2023 ] 	Top5: 8.37%
[ Sat May 13 16:04:44 2023 ] Training epoch: 15
[ Sat May 13 16:07:50 2023 ] 	Mean training loss: 4.1056.  Mean training acc: 1.89%.
[ Sat May 13 16:07:50 2023 ] 	Learning Rate: 0.0883
[ Sat May 13 16:07:50 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:07:51 2023 ] Eval epoch: 15
[ Sat May 13 16:08:16 2023 ] 	Mean test loss of 280 batches: 4.104242384433746.
[ Sat May 13 16:08:16 2023 ] 	Top1: 1.75%
[ Sat May 13 16:08:16 2023 ] 	Top5: 8.89%
[ Sat May 13 16:08:16 2023 ] Training epoch: 16
[ Sat May 13 16:11:22 2023 ] 	Mean training loss: 4.1053.  Mean training acc: 1.71%.
[ Sat May 13 16:11:22 2023 ] 	Learning Rate: 0.0860
[ Sat May 13 16:11:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:11:22 2023 ] Eval epoch: 16
[ Sat May 13 16:11:48 2023 ] 	Mean test loss of 280 batches: 4.10410316160747.
[ Sat May 13 16:11:48 2023 ] 	Top1: 1.72%
[ Sat May 13 16:11:48 2023 ] 	Top5: 7.92%
[ Sat May 13 16:11:48 2023 ] Training epoch: 17
[ Sat May 13 16:14:58 2023 ] 	Mean training loss: 4.1043.  Mean training acc: 1.70%.
[ Sat May 13 16:14:58 2023 ] 	Learning Rate: 0.0835
[ Sat May 13 16:14:58 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:14:59 2023 ] Eval epoch: 17
[ Sat May 13 16:15:25 2023 ] 	Mean test loss of 280 batches: 4.108271961552756.
[ Sat May 13 16:15:25 2023 ] 	Top1: 1.45%
[ Sat May 13 16:15:25 2023 ] 	Top5: 8.62%
[ Sat May 13 16:15:25 2023 ] Training epoch: 18
[ Sat May 13 16:18:40 2023 ] 	Mean training loss: 4.1047.  Mean training acc: 1.80%.
[ Sat May 13 16:18:40 2023 ] 	Learning Rate: 0.0808
[ Sat May 13 16:18:40 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:18:40 2023 ] Eval epoch: 18
[ Sat May 13 16:19:06 2023 ] 	Mean test loss of 280 batches: 4.109114304610661.
[ Sat May 13 16:19:06 2023 ] 	Top1: 1.50%
[ Sat May 13 16:19:06 2023 ] 	Top5: 8.39%
[ Sat May 13 16:19:06 2023 ] Training epoch: 19
[ Sat May 13 16:22:19 2023 ] 	Mean training loss: 4.1046.  Mean training acc: 1.63%.
[ Sat May 13 16:22:19 2023 ] 	Learning Rate: 0.0780
[ Sat May 13 16:22:19 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:22:20 2023 ] Eval epoch: 19
[ Sat May 13 16:22:46 2023 ] 	Mean test loss of 280 batches: 4.098901068312781.
[ Sat May 13 16:22:46 2023 ] 	Top1: 1.39%
[ Sat May 13 16:22:46 2023 ] 	Top5: 8.75%
[ Sat May 13 16:22:46 2023 ] Training epoch: 20
[ Sat May 13 16:26:01 2023 ] 	Mean training loss: 4.1022.  Mean training acc: 1.74%.
[ Sat May 13 16:26:01 2023 ] 	Learning Rate: 0.0750
[ Sat May 13 16:26:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:26:01 2023 ] Eval epoch: 20
[ Sat May 13 16:26:28 2023 ] 	Mean test loss of 280 batches: 4.104656522614615.
[ Sat May 13 16:26:28 2023 ] 	Top1: 1.86%
[ Sat May 13 16:26:28 2023 ] 	Top5: 8.55%
[ Sat May 13 16:26:28 2023 ] Training epoch: 21
[ Sat May 13 16:29:42 2023 ] 	Mean training loss: 4.0999.  Mean training acc: 1.89%.
[ Sat May 13 16:29:42 2023 ] 	Learning Rate: 0.0720
[ Sat May 13 16:29:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:29:43 2023 ] Eval epoch: 21
[ Sat May 13 16:30:08 2023 ] 	Mean test loss of 280 batches: 4.108282097748348.
[ Sat May 13 16:30:08 2023 ] 	Top1: 1.68%
[ Sat May 13 16:30:09 2023 ] 	Top5: 8.84%
[ Sat May 13 16:30:09 2023 ] Training epoch: 22
[ Sat May 13 16:33:24 2023 ] 	Mean training loss: 4.0993.  Mean training acc: 1.53%.
[ Sat May 13 16:33:24 2023 ] 	Learning Rate: 0.0688
[ Sat May 13 16:33:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:33:25 2023 ] Eval epoch: 22
[ Sat May 13 16:33:52 2023 ] 	Mean test loss of 280 batches: 4.108085757493972.
[ Sat May 13 16:33:52 2023 ] 	Top1: 1.48%
[ Sat May 13 16:33:52 2023 ] 	Top5: 8.35%
[ Sat May 13 16:33:52 2023 ] Training epoch: 23
[ Sat May 13 16:37:06 2023 ] 	Mean training loss: 4.1009.  Mean training acc: 1.68%.
[ Sat May 13 16:37:06 2023 ] 	Learning Rate: 0.0655
[ Sat May 13 16:37:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:37:07 2023 ] Eval epoch: 23
[ Sat May 13 16:37:34 2023 ] 	Mean test loss of 280 batches: 4.104081878491811.
[ Sat May 13 16:37:34 2023 ] 	Top1: 1.95%
[ Sat May 13 16:37:34 2023 ] 	Top5: 8.59%
[ Sat May 13 16:37:34 2023 ] Training epoch: 24
[ Sat May 13 16:40:46 2023 ] 	Mean training loss: 4.0993.  Mean training acc: 1.64%.
[ Sat May 13 16:40:46 2023 ] 	Learning Rate: 0.0621
[ Sat May 13 16:40:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:40:47 2023 ] Eval epoch: 24
[ Sat May 13 16:41:12 2023 ] 	Mean test loss of 280 batches: 4.10618074451174.
[ Sat May 13 16:41:12 2023 ] 	Top1: 1.72%
[ Sat May 13 16:41:12 2023 ] 	Top5: 8.64%
[ Sat May 13 16:41:12 2023 ] Training epoch: 25
[ Sat May 13 16:46:36 2023 ] 	Mean training loss: 4.0997.  Mean training acc: 1.88%.
[ Sat May 13 16:46:36 2023 ] 	Learning Rate: 0.0587
[ Sat May 13 16:46:36 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat May 13 16:46:37 2023 ] Eval epoch: 25
[ Sat May 13 16:47:24 2023 ] 	Mean test loss of 280 batches: 4.102051065649305.
[ Sat May 13 16:47:24 2023 ] 	Top1: 1.79%
[ Sat May 13 16:47:24 2023 ] 	Top5: 8.64%
[ Sat May 13 16:47:24 2023 ] Training epoch: 26
[ Sat May 13 16:52:16 2023 ] 	Mean training loss: 4.1013.  Mean training acc: 1.80%.
[ Sat May 13 16:52:16 2023 ] 	Learning Rate: 0.0553
[ Sat May 13 16:52:16 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat May 13 16:52:17 2023 ] Eval epoch: 26
[ Sat May 13 16:52:43 2023 ] 	Mean test loss of 280 batches: 4.1015934143747605.
[ Sat May 13 16:52:43 2023 ] 	Top1: 1.84%
[ Sat May 13 16:52:43 2023 ] 	Top5: 8.53%
[ Sat May 13 16:52:43 2023 ] Training epoch: 27
[ Sat May 13 16:55:56 2023 ] 	Mean training loss: 4.0997.  Mean training acc: 1.77%.
[ Sat May 13 16:55:56 2023 ] 	Learning Rate: 0.0518
[ Sat May 13 16:55:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:55:57 2023 ] Eval epoch: 27
[ Sat May 13 16:56:22 2023 ] 	Mean test loss of 280 batches: 4.10197400535856.
[ Sat May 13 16:56:22 2023 ] 	Top1: 1.70%
[ Sat May 13 16:56:22 2023 ] 	Top5: 8.71%
[ Sat May 13 16:56:22 2023 ] Training epoch: 28
[ Sat May 13 16:59:44 2023 ] 	Mean training loss: 4.0991.  Mean training acc: 1.66%.
[ Sat May 13 16:59:44 2023 ] 	Learning Rate: 0.0483
[ Sat May 13 16:59:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 16:59:45 2023 ] Eval epoch: 28
[ Sat May 13 17:00:27 2023 ] 	Mean test loss of 280 batches: 4.0984089766229905.
[ Sat May 13 17:00:27 2023 ] 	Top1: 1.59%
[ Sat May 13 17:00:28 2023 ] 	Top5: 8.73%
[ Sat May 13 17:00:28 2023 ] Training epoch: 29
[ Sat May 13 17:06:18 2023 ] 	Mean training loss: 4.0975.  Mean training acc: 1.50%.
[ Sat May 13 17:06:18 2023 ] 	Learning Rate: 0.0448
[ Sat May 13 17:06:18 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat May 13 17:06:19 2023 ] Eval epoch: 29
[ Sat May 13 17:07:04 2023 ] 	Mean test loss of 280 batches: 4.099374028614589.
[ Sat May 13 17:07:04 2023 ] 	Top1: 1.63%
[ Sat May 13 17:07:04 2023 ] 	Top5: 8.08%
[ Sat May 13 17:07:05 2023 ] Training epoch: 30
[ Sat May 13 17:12:56 2023 ] 	Mean training loss: 4.0978.  Mean training acc: 1.63%.
[ Sat May 13 17:12:56 2023 ] 	Learning Rate: 0.0414
[ Sat May 13 17:12:56 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat May 13 17:12:57 2023 ] Eval epoch: 30
[ Sat May 13 17:13:33 2023 ] 	Mean test loss of 280 batches: 4.099493229389191.
[ Sat May 13 17:13:33 2023 ] 	Top1: 1.63%
[ Sat May 13 17:13:33 2023 ] 	Top5: 8.08%
[ Sat May 13 17:13:34 2023 ] Training epoch: 31
[ Sat May 13 17:21:16 2023 ] 	Mean training loss: 4.0958.  Mean training acc: 1.70%.
[ Sat May 13 17:21:16 2023 ] 	Learning Rate: 0.0380
[ Sat May 13 17:21:16 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 17:21:17 2023 ] Eval epoch: 31
[ Sat May 13 17:23:01 2023 ] 	Mean test loss of 280 batches: 4.098516614096505.
[ Sat May 13 17:23:01 2023 ] 	Top1: 1.70%
[ Sat May 13 17:23:01 2023 ] 	Top5: 8.77%
[ Sat May 13 17:23:01 2023 ] Training epoch: 32
[ Sat May 13 17:27:22 2023 ] 	Mean training loss: 4.0954.  Mean training acc: 1.45%.
[ Sat May 13 17:27:22 2023 ] 	Learning Rate: 0.0346
[ Sat May 13 17:27:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 17:27:23 2023 ] Eval epoch: 32
[ Sat May 13 17:27:49 2023 ] 	Mean test loss of 280 batches: 4.100051644870213.
[ Sat May 13 17:27:49 2023 ] 	Top1: 1.57%
[ Sat May 13 17:27:49 2023 ] 	Top5: 8.62%
[ Sat May 13 17:27:49 2023 ] Training epoch: 33
[ Sat May 13 17:31:04 2023 ] 	Mean training loss: 4.0932.  Mean training acc: 1.64%.
[ Sat May 13 17:31:04 2023 ] 	Learning Rate: 0.0313
[ Sat May 13 17:31:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 17:31:05 2023 ] Eval epoch: 33
[ Sat May 13 17:31:32 2023 ] 	Mean test loss of 280 batches: 4.1011097601481845.
[ Sat May 13 17:31:32 2023 ] 	Top1: 1.48%
[ Sat May 13 17:31:32 2023 ] 	Top5: 8.24%
[ Sat May 13 17:31:32 2023 ] Training epoch: 34
[ Sat May 13 17:34:48 2023 ] 	Mean training loss: 4.0921.  Mean training acc: 1.77%.
[ Sat May 13 17:34:48 2023 ] 	Learning Rate: 0.0282
[ Sat May 13 17:34:48 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 17:34:48 2023 ] Eval epoch: 34
[ Sat May 13 17:35:15 2023 ] 	Mean test loss of 280 batches: 4.104038001809801.
[ Sat May 13 17:35:15 2023 ] 	Top1: 1.81%
[ Sat May 13 17:35:15 2023 ] 	Top5: 8.26%
[ Sat May 13 17:35:15 2023 ] Training epoch: 35
[ Sat May 13 17:38:49 2023 ] 	Mean training loss: 4.0925.  Mean training acc: 2.05%.
[ Sat May 13 17:38:49 2023 ] 	Learning Rate: 0.0251
[ Sat May 13 17:38:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 17:38:50 2023 ] Eval epoch: 35
[ Sat May 13 17:39:19 2023 ] 	Mean test loss of 280 batches: 4.098852929047176.
[ Sat May 13 17:39:19 2023 ] 	Top1: 1.92%
[ Sat May 13 17:39:19 2023 ] 	Top5: 8.93%
[ Sat May 13 17:39:20 2023 ] Training epoch: 36
[ Sat May 13 17:43:20 2023 ] 	Mean training loss: 4.0899.  Mean training acc: 2.02%.
[ Sat May 13 17:43:20 2023 ] 	Learning Rate: 0.0221
[ Sat May 13 17:43:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 17:43:21 2023 ] Eval epoch: 36
[ Sat May 13 17:43:51 2023 ] 	Mean test loss of 280 batches: 4.10321814928736.
[ Sat May 13 17:43:51 2023 ] 	Top1: 1.84%
[ Sat May 13 17:43:51 2023 ] 	Top5: 8.44%
[ Sat May 13 17:43:51 2023 ] Training epoch: 37
[ Sat May 13 17:47:39 2023 ] 	Mean training loss: 4.0900.  Mean training acc: 1.73%.
[ Sat May 13 17:47:39 2023 ] 	Learning Rate: 0.0193
[ Sat May 13 17:47:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 17:47:39 2023 ] Eval epoch: 37
[ Sat May 13 17:48:15 2023 ] 	Mean test loss of 280 batches: 4.100064429215022.
[ Sat May 13 17:48:15 2023 ] 	Top1: 2.17%
[ Sat May 13 17:48:15 2023 ] 	Top5: 9.02%
[ Sat May 13 17:48:16 2023 ] Training epoch: 38
[ Sat May 13 17:52:39 2023 ] 	Mean training loss: 4.0873.  Mean training acc: 1.88%.
[ Sat May 13 17:52:39 2023 ] 	Learning Rate: 0.0166
[ Sat May 13 17:52:39 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat May 13 17:52:40 2023 ] Eval epoch: 38
[ Sat May 13 17:53:13 2023 ] 	Mean test loss of 280 batches: 4.1036433841500966.
[ Sat May 13 17:53:13 2023 ] 	Top1: 1.90%
[ Sat May 13 17:53:13 2023 ] 	Top5: 8.97%
[ Sat May 13 17:53:13 2023 ] Training epoch: 39
[ Sat May 13 17:57:40 2023 ] 	Mean training loss: 4.0871.  Mean training acc: 2.13%.
[ Sat May 13 17:57:40 2023 ] 	Learning Rate: 0.0141
[ Sat May 13 17:57:40 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 17:57:41 2023 ] Eval epoch: 39
[ Sat May 13 17:58:21 2023 ] 	Mean test loss of 280 batches: 4.102354224239077.
[ Sat May 13 17:58:21 2023 ] 	Top1: 1.90%
[ Sat May 13 17:58:21 2023 ] 	Top5: 9.18%
[ Sat May 13 17:58:21 2023 ] Training epoch: 40
[ Sat May 13 18:02:48 2023 ] 	Mean training loss: 4.0847.  Mean training acc: 2.16%.
[ Sat May 13 18:02:48 2023 ] 	Learning Rate: 0.0118
[ Sat May 13 18:02:48 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat May 13 18:02:49 2023 ] Eval epoch: 40
[ Sat May 13 18:03:24 2023 ] 	Mean test loss of 280 batches: 4.102210320745196.
[ Sat May 13 18:03:24 2023 ] 	Top1: 1.57%
[ Sat May 13 18:03:24 2023 ] 	Top5: 8.28%
[ Sat May 13 18:03:24 2023 ] Training epoch: 41
[ Sat May 13 18:07:06 2023 ] 	Mean training loss: 4.0840.  Mean training acc: 2.06%.
[ Sat May 13 18:07:06 2023 ] 	Learning Rate: 0.0096
[ Sat May 13 18:07:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 18:07:07 2023 ] Eval epoch: 41
[ Sat May 13 18:07:53 2023 ] 	Mean test loss of 280 batches: 4.107927706411907.
[ Sat May 13 18:07:53 2023 ] 	Top1: 1.79%
[ Sat May 13 18:07:53 2023 ] 	Top5: 8.28%
[ Sat May 13 18:07:53 2023 ] Training epoch: 42
[ Sat May 13 18:13:47 2023 ] 	Mean training loss: 4.0826.  Mean training acc: 2.07%.
[ Sat May 13 18:13:47 2023 ] 	Learning Rate: 0.0077
[ Sat May 13 18:13:47 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat May 13 18:13:48 2023 ] Eval epoch: 42
[ Sat May 13 18:14:35 2023 ] 	Mean test loss of 280 batches: 4.104214060306549.
[ Sat May 13 18:14:35 2023 ] 	Top1: 1.68%
[ Sat May 13 18:14:35 2023 ] 	Top5: 8.66%
[ Sat May 13 18:14:35 2023 ] Training epoch: 43
[ Sat May 13 18:20:25 2023 ] 	Mean training loss: 4.0827.  Mean training acc: 2.02%.
[ Sat May 13 18:20:25 2023 ] 	Learning Rate: 0.0060
[ Sat May 13 18:20:25 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat May 13 18:20:26 2023 ] Eval epoch: 43
[ Sat May 13 18:21:01 2023 ] 	Mean test loss of 280 batches: 4.102337586028235.
[ Sat May 13 18:21:01 2023 ] 	Top1: 1.68%
[ Sat May 13 18:21:01 2023 ] 	Top5: 8.93%
[ Sat May 13 18:21:01 2023 ] Training epoch: 44
[ Sat May 13 18:24:15 2023 ] 	Mean training loss: 4.0812.  Mean training acc: 2.21%.
[ Sat May 13 18:24:15 2023 ] 	Learning Rate: 0.0044
[ Sat May 13 18:24:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 18:24:16 2023 ] Eval epoch: 44
[ Sat May 13 18:24:42 2023 ] 	Mean test loss of 280 batches: 4.104832527467183.
[ Sat May 13 18:24:42 2023 ] 	Top1: 1.84%
[ Sat May 13 18:24:42 2023 ] 	Top5: 8.55%
[ Sat May 13 18:24:42 2023 ] Training epoch: 45
[ Sat May 13 18:27:54 2023 ] 	Mean training loss: 4.0791.  Mean training acc: 2.48%.
[ Sat May 13 18:27:54 2023 ] 	Learning Rate: 0.0031
[ Sat May 13 18:27:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 18:27:54 2023 ] Eval epoch: 45
[ Sat May 13 18:28:20 2023 ] 	Mean test loss of 280 batches: 4.10147516812597.
[ Sat May 13 18:28:20 2023 ] 	Top1: 1.97%
[ Sat May 13 18:28:20 2023 ] 	Top5: 8.75%
[ Sat May 13 18:28:20 2023 ] Training epoch: 46
[ Sat May 13 18:31:31 2023 ] 	Mean training loss: 4.0795.  Mean training acc: 2.35%.
[ Sat May 13 18:31:31 2023 ] 	Learning Rate: 0.0020
[ Sat May 13 18:31:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 18:31:32 2023 ] Eval epoch: 46
[ Sat May 13 18:31:57 2023 ] 	Mean test loss of 280 batches: 4.104486959321158.
[ Sat May 13 18:31:57 2023 ] 	Top1: 1.77%
[ Sat May 13 18:31:57 2023 ] 	Top5: 8.97%
[ Sat May 13 18:31:57 2023 ] Training epoch: 47
[ Sat May 13 18:35:10 2023 ] 	Mean training loss: 4.0772.  Mean training acc: 2.30%.
[ Sat May 13 18:35:10 2023 ] 	Learning Rate: 0.0012
[ Sat May 13 18:35:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 18:35:10 2023 ] Eval epoch: 47
[ Sat May 13 18:35:37 2023 ] 	Mean test loss of 280 batches: 4.105288295234953.
[ Sat May 13 18:35:37 2023 ] 	Top1: 1.92%
[ Sat May 13 18:35:37 2023 ] 	Top5: 8.82%
[ Sat May 13 18:35:37 2023 ] Training epoch: 48
[ Sat May 13 18:38:52 2023 ] 	Mean training loss: 4.0764.  Mean training acc: 2.37%.
[ Sat May 13 18:38:52 2023 ] 	Learning Rate: 0.0006
[ Sat May 13 18:38:52 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 18:38:53 2023 ] Eval epoch: 48
[ Sat May 13 18:39:19 2023 ] 	Mean test loss of 280 batches: 4.1071674125535145.
[ Sat May 13 18:39:19 2023 ] 	Top1: 1.90%
[ Sat May 13 18:39:19 2023 ] 	Top5: 8.53%
[ Sat May 13 18:39:20 2023 ] Training epoch: 49
[ Sat May 13 18:42:42 2023 ] 	Mean training loss: 4.0764.  Mean training acc: 2.20%.
[ Sat May 13 18:42:42 2023 ] 	Learning Rate: 0.0002
[ Sat May 13 18:42:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 18:42:43 2023 ] Eval epoch: 49
[ Sat May 13 18:43:12 2023 ] 	Mean test loss of 280 batches: 4.102905073336193.
[ Sat May 13 18:43:12 2023 ] 	Top1: 1.72%
[ Sat May 13 18:43:12 2023 ] 	Top5: 8.50%
[ Sat May 13 18:43:13 2023 ] Training epoch: 50
[ Sat May 13 18:47:08 2023 ] 	Mean training loss: 4.0763.  Mean training acc: 2.44%.
[ Sat May 13 18:47:08 2023 ] 	Learning Rate: 0.0001
[ Sat May 13 18:47:08 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat May 13 18:47:09 2023 ] Eval epoch: 50
[ Sat May 13 18:47:39 2023 ] 	Mean test loss of 280 batches: 4.107569898877825.
[ Sat May 13 18:47:40 2023 ] 	Top1: 1.75%
[ Sat May 13 18:47:40 2023 ] 	Top5: 8.59%
[ Sat May 13 18:48:17 2023 ] Best accuracy: 0.021709937332139658
[ Sat May 13 18:48:17 2023 ] Epoch number: 37
[ Sat May 13 18:48:17 2023 ] Model name: ./work_dir/ntu_hdgcn/cross-subject/joint_CoM_1/
[ Sat May 13 18:48:17 2023 ] Model total number of params: 1659980
[ Sat May 13 18:48:17 2023 ] Weight decay: 0.0004
[ Sat May 13 18:48:17 2023 ] Base LR: 0.1
[ Sat May 13 18:48:17 2023 ] Batch Size: 16
[ Sat May 13 18:48:17 2023 ] Test Batch Size: 16
[ Sat May 13 18:48:17 2023 ] seed: 1
